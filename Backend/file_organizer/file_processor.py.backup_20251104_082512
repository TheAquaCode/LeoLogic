"""
File Processing Pipeline with RAG Generation
"""

import shutil
from pathlib import Path
from config.settings import CONFIDENCE_THRESHOLD
from utils.logger import setup_logger
from utils.move_logger import add_move

logger = setup_logger(__name__)
from .state import state
from .file_extractors import MultiModalExtractor
from .ai_processor import AIProcessor
from .rag_generator import RAGGenerator


def process_file(file_path: str, folder_id: int):
    """
    Complete file processing pipeline:
    1. Extract content (text, images, audio)
    2. Analyze with AI
    3. Classify into category
    4. Generate RAG document
    5. Move to destination
    """
    try:
        logger.info(f"Processing file: {Path(file_path).name}", extra={"file_path": file_path})
        
        # Step 1: Extract all content
        logger.debug("Extracting content...")
        extracted_data = MultiModalExtractor.extract(file_path)
        
        # Step 2: Analyze with AI
        logger.debug("Analyzing with AI...")
        ai_analysis = AIProcessor.analyze_content(extracted_data)
        
        # Step 3: Classify into category
        logger.debug("Classifying...")
        classification = AIProcessor.classify_into_categories(ai_analysis, state.categories)
        category_name = classification["category"]
        confidence = classification["confidence"]
        
        # Check if we have a valid category
        if category_name and confidence >= CONFIDENCE_THRESHOLD:
            category = next((c for c in state.categories if c['name'] == category_name), None)
            
            if category:
                # Step 4: Generate RAG document BEFORE moving
                logger.debug("Generating RAG document...")
                rag_path = RAGGenerator.create_rag_document(
                    file_path,
                    extracted_data,
                    ai_analysis,
                    category_name
                )
                
                # Step 5: Move file to destination
                dest_folder = Path(category['path'])
                dest_folder.mkdir(parents=True, exist_ok=True)
                dest_path = dest_folder / Path(file_path).name
                
                # Handle duplicates
                counter = 1
                while dest_path.exists():
                    dest_path = dest_folder / f"{Path(file_path).stem}_{counter}{Path(file_path).suffix}"
                    counter += 1
                
                shutil.move(file_path, dest_path)
                logger.info(f"Successfully moved to: {dest_path}")
                logger.info(f"Confidence: {confidence:.2%}")
                
                # Update stats
                state.processing_stats["total"] += 1
                state.processing_stats["success"] += 1
                file_type = extracted_data.get("file_type", "other")
                state.processing_stats["by_type"][file_type] = state.processing_stats["by_type"].get(file_type, 0) + 1
                
                return {
                    "status": "success",
                    "file_name": dest_path.name,
                    "category": category_name,
                    "confidence": confidence,
                    "summary": ai_analysis.get("summary", ""),
                    "keywords": ai_analysis.get("keywords", []),
                    "rag_path": rag_path
                }
        
        # Low confidence - generate RAG anyway but don't move
        logger.warning(f"Low confidence: {confidence:.2%}")
        rag_path = RAGGenerator.create_rag_document(
            file_path,
            extracted_data,
            ai_analysis,
            "Uncategorized"
        )
        
        state.processing_stats["total"] += 1
        
        return {
            "status": "low_confidence",
            "file_name": Path(file_path).name,
            "confidence": confidence,
            "summary": ai_analysis.get("summary", ""),
            "suggestions": ai_analysis.get("category_suggestions", []),
            "rag_path": rag_path
        }
    
    except Exception as e:
        logger.error(f"Processing error: {e}", exc_info=True)
        import traceback
        traceback.print_exc()
        
        state.processing_stats["total"] += 1
        state.processing_stats["failed"] += 1
        
        return {
            "status": "error",
            "file_name": Path(file_path).name,
            "error": str(e)
        }
